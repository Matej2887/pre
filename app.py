import streamlit as st
import pandas as pd
import numpy as np
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns
from fpdf import FPDF
import io

# --- KROK 1: VloÅ¾enÃ­ vaÅ¡eho analytickÃ©ho skriptu do cachovanÃ© funkce ---
# Toto zajistÃ­, Å¾e se celÃ½ vÃ½poÄet (vÄetnÄ› generovÃ¡nÃ­ reportu)
# provede pouze jednou, a ne pÅ™i kaÅ¾dÃ© interakci s aplikacÃ­.

@st.cache_data
def load_and_process_data():
    """
    Tato funkce obsahuje celÃ½ vÃ¡Å¡ analytickÃ½ skript.
    SpustÃ­ se jen jednou a vrÃ¡tÃ­ klÃ­ÄovÃ© vÃ½sledky.
    """
    
    # --- 1. Data Acquisition and Preprocessing ---
    # print('--- Krok 1: ZpracovÃ¡nÃ­ a ÄiÅ¡tÄ›nÃ­ dat ---\n') # Printy skryjeme pro Streamlit

    file_name = 'weather_data.csv'
    try:
        df = pd.read_csv(file_name)
        # print(f"ÃšspÄ›Å¡nÄ› naÄten soubor '{file_name}'.")
    except FileNotFoundError:
        # print(f"Chyba: Soubor '{file_name}' nebyl nalezen.")
        # print("VytvÃ¡Å™Ã­m fiktivnÃ­ DataFrame pro demonstraÄnÃ­ ÃºÄely.")
        dates = pd.to_datetime(pd.date_range(start='2000-01-01', periods=100, freq='D'))
        np.random.seed(42)
        dummy_data = {
            'Date': dates,
            'Temperature': np.random.uniform(low=-10, high=35, size=100),
            'WindSpeed': np.random.uniform(low=0, high=30, size=100),
            'Precipitation': np.random.uniform(low=0, high=50, size=100)
        }
        df = pd.DataFrame(dummy_data)

    # Convert 'Date' column to datetime and set as index
    if 'Date' in df.columns:
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.set_index('Date')
        # print('Sloupec "Date" pÅ™eveden na datetime a nastaven jako index.')

    # Ensure the index has frequency information
    df.index = pd.to_datetime(df.index)
    if df.index.freq is None:
        df = df.asfreq('D') # Set frequency to daily
        # print('Frekvence indexu nastavena na dennÃ­ (D).')

    # Handle missing values (ffill then bfill)
    df = df.ffill().bfill()
    # print('ChybÄ›jÃ­cÃ­ hodnoty oÅ¡etÅ™eny pomocÃ­ ffill/bfill.')

    # Outlier Detection and Handling (IQR method - capping)
    columns_to_check = ['Temperature', 'WindSpeed', 'Precipitation']
    for col in columns_to_check:
        if col in df.columns and pd.api.types.is_numeric_dtype(df[col]):
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])
            df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])
    # print('OdlehlÃ© hodnoty oÅ¡etÅ™eny metodou IQR (zastropovÃ¡nÃ­).')

    # print('\n--- Krok 2: VÃ½voj predikÄnÃ­ho modelu a generovÃ¡nÃ­ pÅ™edpovÄ›dÃ­ ---\n')

    # --- 2. Model Development and Predictions ---
    weather_variables = ['Temperature', 'WindSpeed', 'Precipitation']
    es_models = {}
    forecast_results = {}
    long_term_forecast_results = {
        '100_years': {},
        '1000_years': {}
    }
    long_term_forecast_periods = {
        '10_years': 365 * 10,
        '100_years': 365 * 100,
        '1000_years': 365 * 1000
    }

    for col in weather_variables:
        # print(f'ZpracovÃ¡vÃ¡m promÄ›nnou: {col}...')
        series_to_forecast = df[col]

        # Fit ExponentialSmoothing model
        model = sm.tsa.ExponentialSmoothing(
            series_to_forecast,
            trend='add',
            seasonal='add',
            seasonal_periods=7, # Assuming weekly seasonality for short dummy data
            initialization_method="estimated"
        )
        es_fit = model.fit()
        es_models[col] = es_fit

        # Generate 10-year forecast
        forecast_periods_days_10y = long_term_forecast_periods['10_years']
        start_date_forecast_10y = series_to_forecast.index[-1] + pd.Timedelta(days=1)
        end_date_forecast_10y = start_date_forecast_10y + pd.Timedelta(days=forecast_periods_days_10y - 1)
        forecast_index_10y = pd.date_range(start=start_date_forecast_10y, end=end_date_forecast_10y, freq='D')
        forecast_10y = es_fit.forecast(steps=forecast_periods_days_10y)
        forecast_10y.index = forecast_index_10y
        forecast_results[col] = forecast_10y
        # print(f'  - 10letÃ¡ pÅ™edpovÄ›Ä pro {col} vygenerovÃ¡na.')

        # Generate 100-year forecast
        forecast_periods_days_100y = long_term_forecast_periods['100_years']
        start_date_forecast_100y = series_to_forecast.index[-1] + pd.Timedelta(days=1)
        end_date_forecast_100y = start_date_forecast_100y + pd.Timedelta(days=forecast_periods_days_100y - 1)
        forecast_index_100y = pd.date_range(start=start_date_forecast_100y, end=end_date_forecast_100y, freq='D')
        forecast_100y = es_fit.forecast(steps=forecast_periods_days_100y)
        forecast_100y.index = forecast_index_100y
        long_term_forecast_results['100_years'][col] = forecast_100y
        # print(f'  - 100letÃ¡ pÅ™edpovÄ›Ä pro {col} vygenerovÃ¡na.')

        # Generate 1000-year simulated forecast (due to Timestamp overflow limitation)
        forecast_periods_days_1000y = long_term_forecast_periods['1000_years']
        average_historical_value = series_to_forecast.mean()
        synthetic_forecast_values_daily_1000y = np.full(forecast_periods_days_1000y, average_historical_value)
        long_term_forecast_results['1000_years'][col] = synthetic_forecast_values_daily_1000y
        # print(f'  - 1000letÃ¡ simulovanÃ¡ pÅ™edpovÄ›Ä (historickÃ½ prÅ¯mÄ›r) pro {col} vygenerovÃ¡na.')


    # --- 3. Quantify Uncertainties (Approximated Prediction Intervals) ---
    # (Tato ÄÃ¡st nenÃ­ v UI pÅ™Ã­mo pouÅ¾ita, ale je nutnÃ¡ pro report)
    # print('\n--- Krok 3: Kvantifikace nejistot (pÅ™ibliÅ¾nÃ© predikÄnÃ­ intervaly) ---\n')

    def get_approx_prediction_intervals(model_fit, point_forecast_series, historical_df_col):
        resid_std = 0.0
        if hasattr(model_fit, 'resid') and model_fit.resid is not None and len(model_fit.resid) > 1:
            resid_std = model_fit.resid.std()
        if resid_std == 0.0 or np.isnan(resid_std):
            resid_std = historical_df_col.std()
            if resid_std == 0.0 or np.isnan(resid_std):
                resid_std = 0.1
        lower_bound = point_forecast_series - 1.96 * resid_std
        upper_bound = point_forecast_series + 1.96 * resid_std
        pred_int_df = pd.DataFrame({
            'mean': point_forecast_series,
            'mean_ci_lower': lower_bound,
            'mean_ci_upper': upper_bound
        }, index=point_forecast_series.index)
        return pred_int_df

    prediction_intervals_10y = {}
    prediction_intervals_100y = {}
    for col in weather_variables:
        if col in es_models and col in forecast_results:
            model_fit = es_models[col]
            prediction_intervals_10y[col] = get_approx_prediction_intervals(model_fit, forecast_results[col], df[col])
        if col in es_models and col in long_term_forecast_results['100_years']:
            model_fit = es_models[col]
            prediction_intervals_100y[col] = get_approx_prediction_intervals(model_fit, long_term_forecast_results['100_years'][col], df[col])

    # --- 4. GenerovÃ¡nÃ­ reportu (Markdown) ---
    # print('\n--- Krok 4: GenerovÃ¡nÃ­ reportu (Markdown) ---\n')

    # VÃ½poÄet roÄnÃ­ch prÅ¯mÄ›rÅ¯ pro 1000letou pÅ™edpovÄ›Ä (nutnÃ© pro f-string)
    yearly_avg_temp = pd.Series(np.array([long_term_forecast_results['1000_years']['Temperature'][i*365 : (i+1)*365].mean() for i in range(long_term_forecast_periods['1000_years'] // 365)]))
    yearly_avg_wind = pd.Series(np.array([long_term_forecast_results['1000_years']['WindSpeed'][i*365 : (i+1)*365].mean() for i in range(long_term_forecast_periods['1000_years'] // 365)]))
    yearly_avg_precip = pd.Series(np.array([long_term_forecast_results['1000_years']['Precipitation'][i*365 : (i+1)*365].mean() for i in range(long_term_forecast_periods['1000_years'] // 365)]))

    # CelÃ½ vÃ¡Å¡ Markdown report jako f-string
    report_content_markdown = f"""
# PÅ™edpovÄ›Ä poÄasÃ­ pro Brno: 10, 100 a 1000 let

## ShrnutÃ­: KlÃ­ÄovÃ¡ zjiÅ¡tÄ›nÃ­ analÃ½zy dat

* **ZÃ­skÃ¡vÃ¡nÃ­ dat**: PÅ™Ã­mÃ© automatickÃ© zÃ­skÃ¡vÃ¡nÃ­ historickÃ½ch dat o poÄasÃ­ pro Brno nebylo moÅ¾nÃ©, proto byl pro demonstraÄnÃ­ ÃºÄely pouÅ¾it 100dennÃ­ fiktivnÃ­ datovÃ½ soubor. Proces nastÃ­nil manuÃ¡lnÃ­ kroky pro zÃ­skÃ¡nÃ­ reÃ¡lnÃ½ch dat uÅ¾ivateli.
* **PÅ™edzpracovÃ¡nÃ­ a ÄiÅ¡tÄ›nÃ­ dat**: FiktivnÃ­ datovÃ½ soubor proÅ¡el ÄiÅ¡tÄ›nÃ­m, vÄetnÄ› Å™eÅ¡enÃ­ chybÄ›jÃ­cÃ­ch hodnot pomocÃ­ dopÅ™ednÃ©ho a zpÄ›tnÃ©ho vyplÅˆovÃ¡nÃ­ a detekce/omezenÃ­ odlehlÃ½ch hodnot metodou mezikvartilnÃ­ho rozpÄ›tÃ­ (IQR). Sloupec 'Date' byl sprÃ¡vnÄ› formÃ¡tovÃ¡n jako index typu datetime.
* **ExploraÄnÃ­ analÃ½za dat (EDA)**: Byla provedena komplexnÃ­ EDA fiktivnÃ­ch dat, vizualizace historickÃ½ch trendÅ¯, mÄ›sÃ­ÄnÃ­ch prÅ¯mÄ›rÅ¯, distribucÃ­ pomocÃ­ histogramÅ¯ a identifikace potenciÃ¡lnÃ­ch odlehlÃ½ch hodnot pomocÃ­ box plotÅ¯ pro teplotu, rychlost vÄ›tru a srÃ¡Å¾ky.
* **VÃ½zvy pÅ™i vÃ½voji modelu**: PoÄÃ¡teÄnÃ­ pokusy o pouÅ¾itÃ­ knihovny `Prophet` selhaly kvÅ¯li pÅ™etrvÃ¡vajÃ­cÃ­ chybÄ› `AttributeError` (souvisejÃ­cÃ­ se `stan_backend`), coÅ¾ si vyÅ¾Ã¡dalo pÅ™echod na `statsmodels.tsa.ExponentialSmoothing`.
* **10letÃ¡ pÅ™edpovÄ›Ä (Exponential Smoothing)**:
    * **Teplota**: PÅ™edpovÃ­dÃ¡n prÅ¯mÄ›r 26.4Â°C (rozsah: 7.0Â°C aÅ¾ 45.5Â°C), coÅ¾ ukazuje silnÃ½ vzestupnÃ½ trend oproti historickÃ©mu prÅ¯mÄ›ru.
    * **Rychlost vÄ›tru**: PÅ™edpovÃ­dÃ¡n prÅ¯mÄ›r 54.1 m/s (rozsah: 10.7 m/s aÅ¾ 94.6 m/s), coÅ¾ takÃ© naznaÄuje vÃ½znamnÃ½ vzestupnÃ½ trend.
    * **SrÃ¡Å¾ky**: PÅ™edpovÃ­dÃ¡n prÅ¯mÄ›r -833.1 mm (minimum: -1689.5 mm), coÅ¾ je fyzicky nerealistickÃ© a zdÅ¯razÅˆuje kritickÃ© omezenÃ­ neomezenÃ©ho aditivnÃ­ho modelu pro tuto promÄ›nnou v tomto horizontu.
* **100letÃ¡ pÅ™edpovÄ›Ä (Exponential Smoothing)**: Extrapolace aditivnÃ­ho trendu a sezÃ³nnosti vedla k fyzicky nemoÅ¾nÃ½m pÅ™edpovÄ›dÃ­m:
    * **Teplota**: PÅ™edpovÃ­dÃ¡n prÅ¯mÄ›r 159.3Â°C (maximum: 311.3Â°C).
    * **Rychlost vÄ›tru**: PÅ™edpovÃ­dÃ¡n prÅ¯mÄ›r 397.3 m/s (maximum: 781.1 m/s).
    * **SrÃ¡Å¾ky**: PÅ™edpovÃ­dÃ¡n prÅ¯mÄ›r -8506.5 mm (minimum: -17036.8 mm), coÅ¾ dÃ¡le zdÅ¯razÅˆuje nedostateÄnost modelu.
* **1000letÃ¡ pÅ™edpovÄ›Ä (simulovanÃ¡)**: KvÅ¯li chybÃ¡m pÅ™eteÄenÃ­ `pd.Timestamp` a inherentnÃ­m omezenÃ­m `ExponentialSmoothing` pro takto dlouhÃ© horizonty byla pouÅ¾ita simulovanÃ¡ pÅ™edpovÄ›Ä s vyuÅ¾itÃ­m historickÃ©ho prÅ¯mÄ›ru. VÅ¡echny promÄ›nnÃ© se stabilizovaly na svÃ½ch historickÃ½ch prÅ¯mÄ›rech (napÅ™. Teplota ~ 11.16Â°C, rychlost vÄ›tru ~ 14.93 m/s, srÃ¡Å¾ky ~ 25.88 mm) s zanedbatelnou odchylkou, slouÅ¾Ã­cÃ­ spÃ­Å¡e jako zÃ¡stupnÃ© hodnoty neÅ¾ jako skuteÄnÃ© pÅ™edpovÄ›di.
* **Kvantifikace nejistoty**: Pro 10letÃ© a 100letÃ© pÅ™edpovÄ›di byly vygenerovÃ¡ny pÅ™ibliÅ¾nÃ© 95% predikÄnÃ­ intervaly zaloÅ¾enÃ© na standardnÃ­ odchylce reziduÃ­, pÅ™iÄemÅ¾ se uznÃ¡vÃ¡, Å¾e tato metoda pravdÄ›podobnÄ› podceÅˆuje skuteÄnou nejistotu kvÅ¯li rostoucÃ­ chybÄ› na delÅ¡Ã­ch horizontech a pÅ™edpokladÅ¯m konstantnÃ­ variance a normÃ¡lnÃ­ distribuce chyb.
* **OmezenÃ­ souÄasnÃ©ho pÅ™Ã­stupu**: AnalÃ½za zdÅ¯raznila, Å¾e jednoduchÃ© statistickÃ© modely ÄasovÃ½ch Å™ad jsou zÃ¡sadnÄ› nedostateÄnÃ© pro robustnÃ­, fyzicky realistickÃ© dlouhodobÃ© (100 aÅ¾ 1000 let) klimatickÃ© pÅ™edpovÄ›di bez doplnÄ›nÃ­ o domÃ©novÄ› specifickÃ© znalosti, fyzickÃ¡ omezenÃ­ nebo nahrazenÃ­ komplexnÃ­mi, fyzikÃ¡lnÄ› zaloÅ¾enÃ½mi klimatickÃ½mi modely.
* **GenerovÃ¡nÃ­ zprÃ¡vy**: Byla ÃºspÄ›Å¡nÄ› vygenerovÃ¡na komplexnÃ­ zprÃ¡va ve formÃ¡tu Markdown, shrnujÃ­cÃ­ celÃ½ proces, vÄetnÄ› analÃ½zy historickÃ½ch dat, pÅ™edzpracovÃ¡nÃ­, vÃ½voje modelu, kvantifikovanÃ½ch pÅ™edpovÄ›dÃ­ s inherentnÃ­mi omezenÃ­mi a podrobnÃ© diskuse o nejistotÃ¡ch a pÅ™edpokladech.

### ZÃ¡vÄ›ry a dalÅ¡Ã­ kroky

* **VyuÅ¾itÃ­ reÃ¡lnÃ½ch historickÃ½ch dat**: ZÃ­skat a integrovat komplexnÃ­, vÃ­cedecennÃ­ historickÃ¡ data o poÄasÃ­ pro Brno, aby bylo moÅ¾nÃ© smysluplnÄ›jÅ¡Ã­ a robustnÄ›jÅ¡Ã­ trÃ©novÃ¡nÃ­ a validaci modelu, ÄÃ­mÅ¾ se pÅ™ekonajÃ­ omezenÃ­ fiktivnÃ­ch dat.
* **PouÅ¾itÃ­ pokroÄilÃ½ch klimatickÃ½ch modelÅ¯ pro dlouhodobÃ© pÅ™edpovÄ›di**: Pro pÅ™edpovÄ›di pÅ™esahujÃ­cÃ­ 100 nebo 1000 let pÅ™ejÃ­t od statistickÃ½ch modelÅ¯ ÄasovÃ½ch Å™ad k fyzikÃ¡lnÄ› zaloÅ¾enÃ½m klimatickÃ½m modelÅ¯m (napÅ™. modely vÅ¡eobecnÃ© cirkulace), kterÃ© mohou zahrnovat klimatickÃ© sÃ­ly, fyzickÃ¡ omezenÃ­ a poskytovat Å™adu vÄ›rohodnÃ½ch budoucÃ­ch scÃ©nÃ¡Å™Å¯ (napÅ™. scÃ©nÃ¡Å™e IPCC SSP), namÃ­sto spolÃ©hÃ¡nÃ­ se na neomezenÃ© extrapolace.

## Data Acquisition and Preprocessing

Given that direct historical weather data for Brno was not available for automated download, a **dummy dataset** was generated. This synthetic dataset allowed for the demonstration of data preprocessing and model development steps.

Key preprocessing steps included:
- **Missing Value Handling:** Missing values, if present in a real dataset, were addressed using a combination of forward-fill (`ffill()`) and backward-fill (`bfill()`) methods. This strategy assumes that missing data can be reasonably imputed from adjacent observations, which is common for time series data.
- **Outlier Detection and Handling:** Outliers were identified using the **Interquartile Range (IQR) method**. Data points falling outside 1.5 times the IQR from the first (Q1) and third (Q3) quartiles were considered outliers. These outliers were then **capped** at their respective lower or upper bounds to mitigate their undue influence on the model without removing data points entirely. For the dummy data, no outliers were detected after generation.
- **Data Consistency:** The 'Date' column was converted to datetime objects and set as the DataFrame index, ensuring proper time series functionality and frequency setting (daily, 'D'). This step ensures that time-based operations and seasonal analyses are performed correctly.

## Model Development

For long-term forecasting, two primary approaches were considered: `Prophet` and `statsmodels.tsa.ExponentialSmoothing`.

### Initial Attempt with Prophet:
The initial plan was to use Facebook's Prophet library due to its robustness with seasonality and holiday effects. However, an `AttributeError` related to `stan_backend` prevented its successful implementation. This issue typically arises from underlying dependency conflicts or environmental setup challenges with Prophet's C++ backend (Stan). Despite attempts to mitigate this by setting `mcmc_samples=0`, the error persisted, leading to the decision to pivot to an alternative model.

### Chosen Model: statsmodels.tsa.ExponentialSmoothing:
Given the technical difficulties with Prophet, `statsmodels.tsa.ExponentialSmoothing` was selected. This model is suitable for time series data exhibiting both trend and seasonality. Separate models were fitted for each weather variable: Temperature, Wind Speed, and Precipitation.
#### Model Configuration:
- **Trend Component:** An **additive trend** (`trend='add'`) was used. This assumes a linear increase or decrease over time. While simple, it can lead to unrealistic extrapolations over very long horizons if unconstrained.
- **Seasonal Component:** An **additive seasonality** (`seasonal='add'`) was applied. This implies that the seasonal fluctuations have a consistent magnitude irrespective of the series' overall level.
- **Seasonal Period:** For the short 100-day dummy dataset, a **weekly seasonal period** (`seasonal_periods=7`) was used to capture any potential weekly patterns. For a real, multi-year dataset, a yearly seasonality (`seasonal_periods=365`) would be more appropriate.
- **Initialization Method:** `initialization_method='estimated'` was used to allow the model to estimate optimal initial values.

This configuration allowed for the generation of 10-year and 100-year forecasts, with a special handling for the 1000-year horizon due to technical limitations as detailed later.
## Quantified Predictions

### 10-Year Forecast

The 10-year forecast, generated using the Exponential Smoothing model, shows the following characteristics:
- **Temperature:** Mean={forecast_results['Temperature'].describe()['mean']:.2f} (Â±{forecast_results['Temperature'].describe()['std']:.2f}), Range=[{forecast_results['Temperature'].describe()['min']:.2f}, {forecast_results['Temperature'].describe()['max']:.2f}].
  * The model predicts a significant upward trend for temperature, reaching higher values than historically observed.
- **WindSpeed:** Mean={forecast_results['WindSpeed'].describe()['mean']:.2f} (Â±{forecast_results['WindSpeed'].describe()['std']:.2f}), Range=[{forecast_results['WindSpeed'].describe()['min']:.2f}, {forecast_results['WindSpeed'].describe()['max']:.2f}].
  * Similarly, wind speeds show an increasing trend over the decade.
- **Precipitation:** Mean={forecast_results['Precipitation'].describe()['mean']:.2f} (Â±{forecast_results['Precipitation'].describe()['std']:.2f}), Range=[{forecast_results['Precipitation'].describe()['min']:.2f}, {forecast_results['Precipitation'].describe()['max']:.2f}].
  * Precipitation forecasts show physically unrealistic negative values, indicating the model's limitations for this variable over this horizon.

### 100-Year Forecast

Extrapolating the Exponential Smoothing model for 100 years reveals amplified trends:
- **Temperature:** Mean={long_term_forecast_results['100_years']['Temperature'].describe()['mean']:.2f} (Â±{long_term_forecast_results['100_years']['Temperature'].describe()['std']:.2f}), Range=[{long_term_forecast_results['100_years']['Temperature'].describe()['min']:.2f}, {long_term_forecast_results['100_years']['Temperature'].describe()['max']:.2f}].
  * Temperatures reach astronomically high and physically impossible values due to the unconstrained additive trend.
- **WindSpeed:** Mean={long_term_forecast_results['100_years']['WindSpeed'].describe()['mean']:.2f} (Â±{long_term_forecast_results['100_years']['WindSpeed'].describe()['std']:.2f}), Range=[{long_term_forecast_results['100_years']['WindSpeed'].describe()['min']:.2f}, {long_term_forecast_results['100_years']['WindSpeed'].describe()['max']:.2f}].
  * Wind speeds also escalate to highly unrealistic and impossible levels.
- **Precipitation:** Mean={long_term_forecast_results['100_years']['Precipitation'].describe()['mean']:.2f} (Â±{long_term_forecast_results['100_years']['Precipitation'].describe()['std']:.2f}), Range=[{long_term_forecast_results['100_years']['Precipitation'].describe()['min']:.2f}, {long_term_forecast_results['100_years']['Precipitation'].describe()['max']:.2f}].
  * Precipitation values are deeply negative, further highlighting the model's unsuitability for long-term unconstrained predictions.

### 1000-Year Forecast

For the 1000-year horizon, technical limitations (Timestamp overflow) prevented direct daily forecasting with `statsmodels`. Therefore, a **simulated forecast** based on the historical mean was used for visualization, with yearly averages presented:
- **Temperature (Yearly Averages):** Mean={yearly_avg_temp.describe()['mean']:.2f} (Â±{yearly_avg_temp.describe()['std']:.2e}), Range=[{yearly_avg_temp.describe()['min']:.2f}, {yearly_avg_temp.describe()['max']:.2f}].
  * These forecasts revert to the historical mean with negligible variance, serving as a placeholder due to model limitations for such extreme horizons.
- **WindSpeed (Yearly Averages):** Mean={yearly_avg_wind.describe()['mean']:.2f} (Â±{yearly_avg_wind.describe()['std']:.2e}), Range=[{yearly_avg_wind.describe()['min']:.2f}, {yearly_avg_wind.describe()['max']:.2f}].
  * These forecasts revert to the historical mean with negligible variance, serving as a placeholder due to model limitations for such extreme horizons.
- **Precipitation (Yearly Averages):** Mean={yearly_avg_precip.describe()['mean']:.2f} (Â±{yearly_avg_precip.describe()['std']:.2e}), Range=[{yearly_avg_precip.describe()['min']:.2f}, {yearly_avg_precip.describe()['max']:.2f}].
  * These forecasts revert to the historical mean with negligible variance, serving as a placeholder due to model limitations for such extreme horizons.

## Nejistoty, pÅ™edpoklady a omezenÃ­

#### Nejistota v 1000letÃ½ch pÅ™edpovÄ›dÃ­ch
1000letÃ© pÅ™edpovÄ›di teploty, rychlosti vÄ›tru a srÃ¡Å¾ek byly zjednoduÅ¡eny na historickÃ½ prÅ¯mÄ›r fiktivnÃ­ch dat kvÅ¯li technickÃ½m omezenÃ­m. KonkrÃ©tnÄ› `statsmodels.ExponentialSmoothing` nenÃ­ navrÅ¾en pro pÅ™edpovÄ›dnÃ­ horizonty tak extrÃ©mnÃ­, jako je 1000 let s dennÃ­ granularitou, coÅ¾ vede k chybÃ¡m pÅ™eteÄenÃ­ `Timestamp` pÅ™i pokusu o vytvoÅ™enÃ­ dennÃ­ho `DateTimeIndex` pro takto dlouhÃ© obdobÃ­. V dÅ¯sledku toho nebylo moÅ¾nÃ© generovat formÃ¡lnÃ­ predikÄnÃ­ intervaly, kterÃ© se opÃ­rajÃ­ o strukturu chyb modelu. Pro pÅ™edpovÄ›dnÃ­ horizont tisÃ­ciletÃ­ je nejistota obrovskÃ¡ a nelze ji kvantifikovat jednoduchÃ½mi statistickÃ½mi modely ÄasovÃ½ch Å™ad.

KonceptuÃ¡lnÃ­ povaha nejistoty pro takto extrÃ©mnÃ­ horizonty znamenÃ¡, Å¾e jakÃ¡koli jednotlivÃ¡ pÅ™edpovÄ›dnÃ­ hodnota je vysoce spekulativnÃ­. BudoucÃ­ klimatickÃ¡ dynamika je ovlivnÄ›na nesÄetnÃ½mi sloÅ¾itÃ½mi, nelineÃ¡rnÃ­mi interakcemi, vnÄ›jÅ¡Ã­mi vlivy (napÅ™. sluneÄnÃ­ aktivita, sopeÄnÃ© erupce) a zmÄ›nami zpÅ¯sobenÃ½mi ÄlovÄ›kem (napÅ™. emise sklenÃ­kovÃ½ch plynÅ¯, zmÄ›ny ve vyuÅ¾Ã­vÃ¡nÃ­ pÅ¯dy), kterÃ© statistickÃ½ model zaloÅ¾enÃ½ pouze na historickÃ½ch vzorcÃ­ch nemÅ¯Å¾e zachytit. Proto jsou 1000letÃ© pÅ™edpovÄ›di pouze ilustrativnÃ­, odrÃ¡Å¾ejÃ­ pouze prÅ¯mÄ›r krÃ¡tkÃ½ch historickÃ½ch fiktivnÃ­ch dat a nepÅ™edstavujÃ­ vÄ›decky robustnÃ­ dlouhodobou klimatickou projekci.

#### UÄinÄ›nÃ© pÅ™edpoklady
BÄ›hem zpracovÃ¡nÃ­ dat a vÃ½voje modelu byly uÄinÄ›ny nÃ¡sledujÃ­cÃ­ pÅ™edpoklady:

* **PÅ™edzpracovÃ¡nÃ­ dat:**
    * **ChybÄ›jÃ­cÃ­ hodnoty:** PÅ™edpoklÃ¡dalo se, Å¾e dopÅ™ednÃ© vyplÅˆovÃ¡nÃ­ (`ffill`) nÃ¡sledovanÃ© zpÄ›tnÃ½m vyplÅˆovÃ¡nÃ­m (`bfill`) je vhodnou strategiÃ­ pro zpracovÃ¡nÃ­ chybÄ›jÃ­cÃ­ch hodnot. To pÅ™edpoklÃ¡dÃ¡, Å¾e chybÄ›jÃ­cÃ­ datovÃ© body jsou nejlÃ©pe aproximovÃ¡ny nejnovÄ›jÅ¡Ã­mi nebo nejbliÅ¾Å¡Ã­mi dostupnÃ½mi daty, coÅ¾ nemusÃ­ platit pro vÅ¡echny typy meteorologickÃ½ch dat nebo pro dlouhÃ© mezery.
    * **OdlehlÃ© hodnoty:** Pro detekci odlehlÃ½ch hodnot byla pouÅ¾ita metoda **mezikvartilnÃ­ho rozpÄ›tÃ­ (IQR)** s nÃ¡sobitelem 1,5x IQR a odlehlÃ© hodnoty byly **zastropovÃ¡ny** na jejich dolnÃ­ch nebo hornÃ­ch mezÃ­ch. To pÅ™edpoklÃ¡dÃ¡, Å¾e extrÃ©mnÃ­ hodnoty jsou buÄ chyby, nebo Å¾e jejich dopad by mÄ›l bÃ½t zmÃ­rnÄ›n jejich omezenÃ­m, spÃ­Å¡e neÅ¾ aby byly povaÅ¾ovÃ¡ny za skuteÄnÃ©, byÅ¥ vzÃ¡cnÃ©, udÃ¡losti nebo zcela odstranÄ›ny.
    * **Frekvence dat:** PÅ™edpoklÃ¡dalo se, Å¾e data majÃ­ dennÃ­ frekvenci ('D'), kterÃ¡ byla explicitnÄ› nastavena pro index DataFrame.

* **VÃ½voj modelu (ExponentialSmoothing):**
    * **VÃ½bÄ›r modelu:** `ExponentialSmoothing` byl vybrÃ¡n jako robustnÃ­ univerzÃ¡lnÃ­ model ÄasovÃ½ch Å™ad, schopnÃ½ zachytit trend i sezÃ³nnost. To pÅ™edpoklÃ¡dÃ¡, Å¾e budoucÃ­ vzorce budou obecnÄ› nÃ¡sledovat prodlouÅ¾enÃ­ minulÃ½ch vzorcÅ¯.
    * **TrendovÃ¡ sloÅ¾ka:** Byla pÅ™edpoklÃ¡dÃ¡na **aditivnÃ­ trendovÃ¡ sloÅ¾ka** (`trend='add'`). To znamenÃ¡, Å¾e trendovÃ¡ sloÅ¾ka pÅ™idÃ¡vÃ¡ konstantnÃ­ mnoÅ¾stvÃ­ k pÅ™edpovÄ›di v kaÅ¾dÃ©m obdobÃ­, coÅ¾ mÅ¯Å¾e vÃ©st k neomezenÃ©mu a nerealistickÃ©mu rÅ¯stu nebo poklesu v dlouhÃ½ch obdobÃ­ch.
    * **SezÃ³nnÃ­ sloÅ¾ka:** Byla pouÅ¾ita **aditivnÃ­ sezÃ³nnost** (`seasonal='add'`). To znamenÃ¡, Å¾e sezÃ³nnÃ­ vÃ½kyvy majÃ­ konstantnÃ­ velikost bez ohledu na ÃºroveÅˆ Å™ady.
    * **SezÃ³nnÃ­ obdobÃ­:** Pro krÃ¡tkÃ½ 100dennÃ­ fiktivnÃ­ datovÃ½ soubor bylo pouÅ¾ito tÃ½dennÃ­ sezÃ³nnÃ­ obdobÃ­ (`seasonal_periods=7`). Pro reÃ¡lnÃ¡, vÃ­celetÃ¡ meteorologickÃ¡ data by bylo typicky vhodnÄ›jÅ¡Ã­ roÄnÃ­ sezÃ³nnÃ­ obdobÃ­ (`seasonal_periods=365`).
    * **Distribuce chyb:** VÃ½poÄet pÅ™ibliÅ¾nÃ½ch 95% predikÄnÃ­ch intervalÅ¯ pÅ™edpoklÃ¡dÃ¡, Å¾e chyby pÅ™edpovÄ›di jsou normÃ¡lnÄ› rozdÄ›leny a majÃ­ konstantnÃ­ rozptyl, coÅ¾ je v reÃ¡lnÃ½ch ÄasovÃ½ch Å™adÃ¡ch Äasto poruÅ¡eno, zejmÃ©na u delÅ¡Ã­ch horizontÅ¯, kde se nejistota typicky zvyÅ¡uje.

#### ZjiÅ¡tÄ›nÃ¡ omezenÃ­
BÄ›hem procesu bylo zjiÅ¡tÄ›no nÄ›kolik vÃ½znamnÃ½ch omezenÃ­:

* **Chyba knihovny Prophet:** Chyba `AttributeError: 'Prophet' object has no attribute 'stan_backend'` zabrÃ¡nila pouÅ¾itÃ­ modelu `Prophet`. To Äasto poukazuje na problÃ©my s prostÅ™edÃ­m nebo zÃ¡vislostmi, kterÃ© nemohly bÃ½t vyÅ™eÅ¡eny v rÃ¡mci provÃ¡dÄ›nÃ­ notebooku, coÅ¾ si vynutilo pÅ™echod na `statsmodels.ExponentialSmoothing`.
* **`statsmodels.ExponentialSmoothing` pro dlouhodobÃ© pÅ™edpovÄ›di:**
    * **Fyzicky nerealistickÃ© pÅ™edpovÄ›di:** AditivnÃ­ trendovÃ¡ sloÅ¾ka v modelu `ExponentialSmoothing`, pÅ™i extrapolaci na 10letÃ© a zejmÃ©na 100letÃ© horizonty, vedla k fyzicky nerealistickÃ½m pÅ™edpovÄ›dÃ­m. NapÅ™Ã­klad:
        * **Teplota a rychlost vÄ›tru:** Hodnoty se staly nadmÄ›rnÄ› vysokÃ½mi (napÅ™. teploty nad 150Â°C, rychlosti vÄ›tru blÃ­zkÃ© rychlosti zvuku), coÅ¾ je nemoÅ¾nÃ©.
        * **SrÃ¡Å¾ky:** PÅ™edpovÄ›di srÃ¡Å¾ek se staly vÃ½znamnÄ› zÃ¡pornÃ½mi, coÅ¾ je fyzicky nemoÅ¾nÃ©.
    * **Nedostatek omezenÃ­:** Model postrÃ¡dÃ¡ mechanismy pro uvalenÃ­ fyzickÃ½ch omezenÃ­ (napÅ™. teplotnÃ­ meze, nezÃ¡pornÃ© srÃ¡Å¾ky) bÄ›hem pÅ™edpovÄ›di, coÅ¾ jej ÄinÃ­ nevhodnÃ½m pro neomezenou dlouhodobou extrapolaci bez ruÄnÃ­ho dodateÄnÃ©ho zpracovÃ¡nÃ­ nebo sofistikovanÄ›jÅ¡Ã­ho nÃ¡vrhu modelu.
* **PÅ™eteÄenÃ­ `pd.Timestamp` pro 1000letÃ© `date_range`:** Pokus o vytvoÅ™enÃ­ dennÃ­ho `pd.date_range` nebo objektÅ¯ `pd.Timestamp` pro 1000letÃ© obdobÃ­ vedl k chybÄ› pÅ™eteÄenÃ­. To naznaÄuje, Å¾e `DateTimeIndex` v knihovnÄ› pandas (kterÃ½ pouÅ¾Ã­vÃ¡ rozliÅ¡enÃ­ nanosekund) mÃ¡ omezenÃ­ pro extrÃ©mnÄ› vzdÃ¡lenÃ¡ budoucÃ­ data.
* **PÅ™ibliÅ¾nÃ© predikÄnÃ­ intervaly:** Vzhledem k tomu, Å¾e API `statsmodels` pÅ™Ã­mo neposkytuje metodu `get_prediction` se standardnÃ­m parametrem `alpha` pro `HoltWintersResultsWrapper` nebo `predict` s `return_everything=True`, musely bÃ½t 95% predikÄnÃ­ intervaly aproximovÃ¡ny pomocÃ­ smÄ›rodatnÃ© odchylky reziduÃ­. Tato metoda je zjednoduÅ¡enÃ­ a obecnÄ› podceÅˆuje skuteÄnou nejistotu, zejmÃ©na s rostoucÃ­m predikÄnÃ­m horizontem.
* **KrÃ¡tkÃ½ fiktivnÃ­ datovÃ½ soubor:** SpolÃ©hÃ¡nÃ­ se na 100dennÃ­ fiktivnÃ­ datovÃ½ soubor vÃ½znamnÄ› omezilo schopnost robustnÄ› pÅ™izpÅ¯sobit modely s dlouhÃ½mi sezÃ³nnÃ­mi obdobÃ­mi (jako je roÄnÃ­ sezÃ³nnost) a zÃ­skat smysluplnÃ© dlouhodobÃ© pÅ™edpovÄ›di. ReÃ¡lnÃ¡ klimatickÃ¡ data se typicky rozprostÃ­rajÃ­ pÅ™es mnoho desetiletÃ­ aÅ¾ staletÃ­.

#### Dopad omezenÃ­ na spolehlivost a interpretaci

OmezenÃ­ vÃ¡Å¾nÄ› ovlivÅˆujÃ­ spolehlivost a interpretaci dlouhodobÃ½ch pÅ™edpovÄ›dÃ­:

* **10letÃ¡ pÅ™edpovÄ›Ä:** ZatÃ­mco vykazuje vÄ›rohodnÃ© trendy, pÅ™edpovÄ›Ä srÃ¡Å¾ek stÃ¡le ukazuje neplatnÃ© zÃ¡pornÃ© hodnoty, coÅ¾ naznaÄuje, Å¾e i pro desetiletÃ­ se aditivnÃ­ pÅ™edpoklady modelu mohou pro urÄitÃ© promÄ›nnÃ© zhroutit.
* **100letÃ¡ pÅ™edpovÄ›Ä:** Tyto pÅ™edpovÄ›di jsou vysoce nespolehlivÃ© a fyzicky nemoÅ¾nÃ© pro teplotu, rychlost vÄ›tru a srÃ¡Å¾ky. JasnÄ› ukazujÃ­, Å¾e jednoduchÃ© statistickÃ© modely navrÅ¾enÃ© pro krÃ¡tkodobÃ© aÅ¾ stÅ™ednÄ›dobÃ© pÅ™edpovÄ›di jsou zcela nedostateÄnÃ© pro stoletÃ© klimatickÃ© projekce bez zÃ¡sadnÃ­ch Ãºprav nebo integrace s fyzikÃ¡lnÄ› zaloÅ¾enou klimatologiÃ­.
* **1000letÃ¡ pÅ™edpovÄ›Ä:** ExplicitnÃ­ zjednoduÅ¡enÃ­ na historickÃ½ prÅ¯mÄ›r kvÅ¯li technickÃ½m omezenÃ­m zbavuje tyto pÅ™edpovÄ›di skuteÄnÃ© prediktivnÃ­ sÃ­ly nad rÃ¡mec odrazu prÅ¯mÄ›ru historickÃ©ho vstupu. SlouÅ¾Ã­ spÃ­Å¡e jako zÃ¡stupnÃ½ symbol, zdÅ¯razÅˆujÃ­cÃ­ extrÃ©mnÃ­ obtÃ­Å¾nost a potÅ™ebu zcela odliÅ¡nÃ½ch modelovacÃ­ch paradigmat (napÅ™. modely systÃ©mu ZemÄ›) pro takovÃ© ÄasovÃ© mÄ›Å™Ã­tko. Absence Å™Ã¡dnÃ© kvantifikace nejistoty dÃ¡le sniÅ¾uje jejich uÅ¾iteÄnost.

ZÃ¡vÄ›rem, zatÃ­mco statistickÃ© modely ÄasovÃ½ch Å™ad, jako je Exponential Smoothing, mohou bÃ½t uÅ¾iteÄnÃ© pro krÃ¡tkodobÃ© pÅ™edpovÄ›di a identifikaci vzorcÅ¯, jsou zÃ¡sadnÄ› nedostateÄnÃ© pro robustnÃ­ a fyzicky realistickÃ© dlouhodobÃ© (100 aÅ¾ 1000 let) klimatickÃ© pÅ™edpovÄ›di, pokud nejsou doplnÄ›ny o znalosti specifickÃ© pro danou oblast, fyzickÃ¡ omezenÃ­ nebo nahrazeny komplexnÃ­mi, fyzikÃ¡lnÄ› zaloÅ¾enÃ½mi klimatickÃ½mi modely.
"""

    # VracÃ­me klÃ­ÄovÃ© objekty, kterÃ© budeme potÅ™ebovat v UI
    return df, forecast_results, long_term_forecast_results, report_content_markdown

# --- PomocnÃ¡ funkce pro generovÃ¡nÃ­ PDF ---
def create_pdf_bytes(text):
    """
    VytvoÅ™Ã­ PDF z textovÃ©ho Å™etÄ›zce a vrÃ¡tÃ­ ho jako bytes.
    PouÅ¾Ã­vÃ¡ zÃ¡kladnÃ­ kÃ³dovÃ¡nÃ­ 'latin-1' s nahrazenÃ­m znakÅ¯,
    aby se zabrÃ¡nilo chybÃ¡m s Äeskou diakritikou, kterÃ¡ nenÃ­ v zÃ¡kladu FPDF.
    VÃ½slednÃ© PDF nemusÃ­ zobrazit diakritiku sprÃ¡vnÄ›, ale nespadne.
    """
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", size=10)
    
    # PÅ™evede text na kÃ³dovÃ¡nÃ­, kterÃ© FPDF zvlÃ¡dne, nahradÃ­ neznÃ¡mÃ© znaky
    safe_text = text.encode('latin-1', 'replace').decode('latin-1')
    
    pdf.multi_cell(0, 5, safe_text)
    return pdf.output() # VrÃ¡tÃ­ data jako bytes


# --- KROK 2: VytvoÅ™enÃ­ samotnÃ© Streamlit aplikace ---

st.set_page_config(page_title="PÅ™edpovÄ›Ä poÄasÃ­", layout="wide")
st.title("PÅ™edpovÄ›Ä poÄasÃ­ pro Brno")

# NaÄtenÃ­ dat (dÃ­ky cache se to provede rychle)
try:
    with st.spinner("ProvÃ¡dÃ­m analÃ½zu dat a trÃ©nuji modely..."):
        df_hist, fc_10y, fc_long, report_md = load_and_process_data()

    st.success("AnalÃ½za dokonÄena!")

    # --- Sekce 1: InteraktivnÃ­ graf teplot ---
    st.header("ğŸ“ˆ InteraktivnÃ­ prÅ¯zkum teplot (10letÃ¡ pÅ™edpovÄ›Ä)")

    # SpojenÃ­ historickÃ½ch dat a 10letÃ© pÅ™edpovÄ›di pro graf
    temp_hist = df_hist['Temperature']
    temp_fc = fc_10y['Temperature']
    full_temp_series = pd.concat([temp_hist, temp_fc])
    full_temp_series.name = "Teplota"

    # VÃ½bÄ›r data
    min_date = full_temp_series.index.min().date()
    max_date = full_temp_series.index.max().date()
    
    # VÃ½chozÃ­ rozsah: poslednÃ­ rok historie + prvnÃ­ 2 roky pÅ™edpovÄ›di
    default_start = temp_hist.index.max().date() - pd.DateOffset(years=1)
    default_end = temp_hist.index.max().date() + pd.DateOffset(years=2)

    selected_dates = st.date_input(
        "Vyberte ÄasovÃ© obdobÃ­:",
        value=(default_start, default_end),
        min_value=min_date,
        max_value=max_date
    )

    if len(selected_dates) == 2:
        start_date, end_date = selected_dates
        
        # FiltrovÃ¡nÃ­ dat podle vÃ½bÄ›ru
        filtered_data = full_temp_series.loc[start_date:end_date]
        
        st.subheader(f"VÃ½voj teploty od {start_date} do {end_date}")
        
        # ZobrazenÃ­ grafu
        st.line_chart(filtered_data)
        
        # ZobrazenÃ­ surovÃ½ch dat
        with st.expander("Zobrazit surovÃ¡ data pro vybranÃ© obdobÃ­"):
            st.dataframe(filtered_data.to_frame())
    else:
        st.warning("ProsÃ­m, vyberte poÄÃ¡teÄnÃ­ i koneÄnÃ© datum.")

    
    # --- Sekce 2: PDF Report ---
    st.markdown("---")
    st.header("ğŸ“„ ZÃ¡vÄ›reÄnÃ½ report a staÅ¾enÃ­ PDF")

    # VygenerovÃ¡nÃ­ PDF v pamÄ›ti
    pdf_data = create_pdf_bytes(report_md)
    
    # TlaÄÃ­tko ke staÅ¾enÃ­
    st.download_button(
        label="StÃ¡hnout kompletnÃ­ report jako PDF",
        data=pdf_data,
        file_name="predpoved_pocasi_report.pdf",
        mime="application/pdf"
    )

    st.info("""
    **PoznÃ¡mka:** VygenerovanÃ© PDF obsahuje surovÃ½ text zprÃ¡vy. KvÅ¯li omezenÃ­m zÃ¡kladnÃ­ knihovny FPDF 
    nemusÃ­ bÃ½t ÄeskÃ¡ diakritika v PDF souboru zobrazena sprÃ¡vnÄ›. 
    Pro nejlepÅ¡Ã­ zobrazenÃ­ si proÄtÄ›te nÃ¡hled reportu pÅ™Ã­mo zde v aplikaci.
    """)

    # ZobrazenÃ­ nÃ¡hledu Markdown reportu
    with st.expander("Zobrazit nÃ¡hled reportu v aplikaci", expanded=True):
        st.markdown(report_md)

except Exception as e:
    st.error(f"DoÅ¡lo k chybÄ› pÅ™i zpracovÃ¡nÃ­ dat: {e}")
    st.exception(e)
